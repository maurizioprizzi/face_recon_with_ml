{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eba29cee-8559-4c13-b466-2a16cb1d0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d63e019-178b-4083-bfa2-005597374723",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = glob('./data/female/*.jpg') # female path\n",
    "mpath = glob('./data/male/*.jpg') # male path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91e096a8-4abb-4c4d-85ea-baffa26ccfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in the Female folder is =  4762\n",
      "The number of images in the Male folder is =  5399\n"
     ]
    }
   ],
   "source": [
    "print('The number of images in the Female folder is = ', len(fpath))\n",
    "print('The number of images in the Male folder is = ', len(mpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7b69183-e287-4167-8539-52131aa8b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar = cv2.CascadeClassifier('./model/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e6c6c1-8adf-4d63-aa9e-6382dfaa1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image_paths, gender):\n",
    "    \"\"\"\n",
    "    Processa imagens e salva rostos recortados na pasta correta.\n",
    "    \n",
    "    :param image_paths: Lista de caminhos das imagens a serem processadas.\n",
    "    :param gender: Tipo de imagem ('female' ou 'male') para salvar na pasta correspondente.\n",
    "    \"\"\"\n",
    "    for i in range(len(image_paths)):\n",
    "        try:\n",
    "            ### Step 1 - Read image and convert to RGB\n",
    "            img = cv2.imread(image_paths[i])  # Read img in BGR\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        \n",
    "            ### Step 2 - Apply Haar Cascade Classifier\n",
    "            gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "            faces_list = haar.detectMultiScale(gray, 1.5, 5)\n",
    "            \n",
    "            for x, y, w, h in faces_list:\n",
    "                ### Step 3 - Crop face\n",
    "                roi = img[y:y + h, x:x + w]  # Region of interest\n",
    "                \n",
    "                ### Step 4 - Save image\n",
    "                cv2.imwrite(f'./crop_data/{gender}/{gender}_{i}.jpg', roi)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'Unable to process the image {image_paths[i]}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c87034cb-33a8-4343-a588-69a2441ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para processar imagens femininas:\n",
    "process_images(fpath, 'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc31b01-0756-4120-a884-66c34e0f9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para processar imagens masculinas:\n",
    "process_images(mpath, 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230e05f-da71-4c5c-b379-0427b40c3c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
